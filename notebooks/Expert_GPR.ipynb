{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Demo\n",
    "\n",
    "This notebook briefly describes how to make an variational inference with Henbun.\n",
    "\n",
    "*Keisuke Fujii, 21st Nov. 2016*\n",
    "\n",
    "We show \n",
    "+ Expert model with Gaussian process prior  \n",
    "that is much more flexible than the simple Gaussian process regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import Henbun as hb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0,6,150).reshape(-1,1)\n",
    "Y = np.sin(0.1*X*X*X) + np.random.randn(*X.shape)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(X,Y,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a Henbun model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we demonstrate the expert model by Henbun. \n",
    "\n",
    "We assume three latent functions, one of which has the shorter lengthscale ($f_s(x)$), another with longer lengthscale ($f_l(x)$).\n",
    "The last one has largest lengthscale, $r(x)$ and represents the fraction of $f_s(x)$ and $f_l(x)$ to be contributed with respect to the position, i.e.\n",
    "$$\n",
    "f(x) = \\frac{1}{1+e^{r(x)}} f_s(x) + \\frac{1}{1+e^{-r(x)}} f_l(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Any model should inherite hb.model.Model\n",
    "class ExpertGPR(hb.model.Model):\n",
    "    def setUp(self):\n",
    "        \"\"\" \n",
    "        Set up parameters and Data for this model.\n",
    "        Model.setUp is immediately called after Model.__init__()\n",
    "        \"\"\"\n",
    "        # Data should be stored in hb.param.Data class. \n",
    "        self.X = hb.param.Data(X)\n",
    "        self.Y = hb.param.Data(Y)\n",
    "        \n",
    "        # Variational parameters. \n",
    "        # We assume posterior of f_s, f_l, r are independent.\n",
    "        self.q_s = hb.variationals.Gaussian(shape=X.shape, q_shape='fullrank')\n",
    "        self.q_l = hb.variationals.Gaussian(shape=X.shape, q_shape='fullrank')\n",
    "        self.q_r = hb.variationals.Gaussian(shape=X.shape, q_shape='fullrank')\n",
    "        \n",
    "        # Kernel object for GPR. \n",
    "        self.kern_s = hb.gp.kernels.UnitRBF(np.ones(1)*0.2)\n",
    "        self.kern_l = hb.gp.kernels.UnitRBF(np.ones(1)*1)\n",
    "        self.kern_r = hb.gp.kernels.UnitRBF(np.ones(1)*1)\n",
    "        # Since our kernel does not contain the variance term, we multiply by hand.\n",
    "        # The variance parameter should be positive.\n",
    "        # It is possible to constrain k_var to stay in positive space by setting\n",
    "        # transform option.\n",
    "        self.k_var = hb.param.Variable(shape=[1], transform=hb.transforms.positive)\n",
    "        self.k_var_r = hb.param.Variable(shape=[1], transform=hb.transforms.positive)\n",
    "        \n",
    "        # likelihood variance\n",
    "        self.var = hb.param.Variable(shape=[1], transform=hb.transforms.positive)\n",
    "        \n",
    "    @hb.model.AutoOptimize()\n",
    "    def ELBO(self):\n",
    "        \"\"\"\n",
    "        We calculate ELBO that should be maximized in this method.\n",
    "        \"\"\"\n",
    "        # f_s, f_l, f_r is the latent function.\n",
    "        # Here, we assign them as a member of this class, \n",
    "        # which makes it easy to draw the result later.\n",
    "        self.f_s = tf.matmul(self.kern_s.Cholesky(self.X), self.q_s)\n",
    "        self.f_l = tf.matmul(self.kern_l.Cholesky(self.X), self.q_l)\n",
    "        self.f_r = tf.matmul(self.kern_r.Cholesky(self.X), self.q_r) * tf.sqrt(self.k_var_r)\n",
    "        \n",
    "        fraction = tf.sigmoid(self.f_r)\n",
    "        self.f = (fraction * self.f_s + (1-fraction) * self.f_l)*self.k_var\n",
    "        # Kulback-Leibler divergence can be accessed by self.KL() method.\n",
    "        return tf.reduce_sum(hb.densities.gaussian(self.Y, self.f, self.var))\\\n",
    "                - self.KL()\n",
    "        \n",
    "    @hb.model.AutoOptimize()\n",
    "    def ELBO_single(self):\n",
    "        \"\"\"\n",
    "        We carry out a usual GPR as an initial estimate.\n",
    "        \"\"\"\n",
    "        # f_s, f_l, f_r is the latent function.\n",
    "        # Here, we assign them as a member of this class, \n",
    "        # which makes it easy to draw the result later.\n",
    "        f_s = tf.matmul(self.kern_s.Cholesky(self.X), self.q_s)*self.k_var\n",
    "        # Kulback-Leibler divergence can be accessed by self.KL() method.\n",
    "        return tf.reduce_sum(hb.densities.gaussian(self.Y, f_s, self.var))\\\n",
    "                - self.KL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExpertGPR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Henbun model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric issue\n",
    "We adopt float64 bit computation, although float 32 bit computation is adopted by default.\n",
    "For changing the float type, we can change by setting method.\n",
    "\n",
    "Henbun adopted config structure adopted in GPflow.\n",
    "See https://github.com/GPflow/GPflow/blob/master/doc/source/notebooks/settings.ipynb for the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can change configuration from setting module\n",
    "custom_config = hb.settings.get_settings()\n",
    "custom_config.numerics.jitter_level = 3.0e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial optimization\n",
    "\n",
    "We make an initial estimate by fitting data by a single Gaussian Proces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# During the compilation, we adopt context manager by temp_setting\n",
    "with hb.settings.temp_settings(custom_config):\n",
    "    model.ELBO_single().compile(tf.train.AdamOptimizer(0.01))\n",
    "    model.ELBO_single().optimize(maxiter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.kern_s.lengthscales.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adopt the initial estimates.\n",
    "\n",
    "We copy from the above estimate into model.q_l and model.kern_l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.q_l.q_mu = model.q_s.q_mu.value\n",
    "model.q_l.q_sqrt = model.q_s.q_sqrt.value\n",
    "model.kern_l.lengthscales = model.kern_s.lengthscales.value + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# During the compilation, we adopt context manager by temp_setting\n",
    "with hb.settings.temp_settings(custom_config):\n",
    "    # First, we need compilation of the model\n",
    "    model.ELBO().compile(tf.train.AdamOptimizer(0.001))\n",
    "    # To evaluate this method with current parameters, run() method can be used.\n",
    "    model.ELBO().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "logf = []\n",
    "for i in range(1000):    \n",
    "    try:\n",
    "        # run 10 iteration\n",
    "        model.ELBO().optimize(maxiter=10)\n",
    "        obj = model.ELBO().run()\n",
    "        logf.append(obj)\n",
    "        # display\n",
    "        if (i % 10) ==0:\n",
    "            plt.clf()\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.plot(logf, '-ko', markersize=3, linewidth=1)\n",
    "            plt.ylabel('ELBO')\n",
    "            plt.xlabel('iteration')\n",
    "            ymin = np.percentile(logf, 10)\n",
    "            ymax = np.max(logf) + (np.max(logf)-ymin)*0.1\n",
    "            plt.ylim(ymin, ymax)\n",
    "            # --- plot for self. ---\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.scatter(X, Y, facecolors='none', edgecolors='b', label='data')\n",
    "            for s in range(30):\n",
    "                plt.plot(X, model.run(model.f), 'k', alpha=0.2)\n",
    "            plt.ylim(-2,2)\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw samples from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.scatter(X, Y, facecolors='none', edgecolors='b', label='data')\n",
    "for s in range(30):\n",
    "    plt.plot(X, model.run(model.f), 'k', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "for s in range(50):\n",
    "    plt.plot(X, model.run(model.f_r), 'k', alpha=0.2)\n",
    "plt.title('$f_r$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "for s in range(50):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(X, model.run(model.f_s), 'k', alpha=0.2)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(X, model.run(model.f_l), 'k', alpha=0.2)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('$f_s$')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('$f_l$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
