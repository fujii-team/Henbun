{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of Henbun\n",
    "\n",
    "This notebook describes structure of Henbun and how to construct a model with it.  \n",
    "We construct a linear model as an example.\n",
    "\n",
    "Note that *Henbun* is not very effective for such a very simple model.  \n",
    "This example is just to present Henbun's structure and its main functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import Henbun as hb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0,6,40).reshape(-1,1)\n",
    "Y = 0.5*X + np.random.randn(40,1)*0.3 + 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(X, Y, 'o', label='data')\n",
    "plt.plot(X, 0.5*X+0.4, '--k', label='true')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Fit Model\n",
    "\n",
    "We assume the data $y_i$ has a linear relation with input $x_i$.\n",
    " \n",
    "$$y_i \\sim a + b x_i$$\n",
    "\n",
    "with coefficients a and b.\n",
    "\n",
    "We seek $a$ and $b$ that minimizes the following loss\n",
    "$$\n",
    "\\mathrm{Loss} = \\sum_i{(y_i - (a + b * x_i))^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a linear fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LinearFit(hb.model.Model):\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        This method is called just after the instanciation of this class.\n",
    "        In this method, we need to define any variables and data to be used in this model.\n",
    "        \"\"\"\n",
    "        # data should be stored in hb.param.Data class\n",
    "        self.X = hb.param.Data(X)\n",
    "        self.Y = hb.param.Data(Y)\n",
    "        \n",
    "        # Parameters that are defined as hb.param.Variable will be optimized by this model.\n",
    "        self.a = hb.param.Variable(shape=[1])\n",
    "        self.b = hb.param.Variable(shape=[1])\n",
    "        \n",
    "    @hb.model.AutoOptimize()\n",
    "    def MinusLoss(self):\n",
    "        \"\"\"\n",
    "        Any method decorated by @AutoOptimize can be optimized.\n",
    "        Here we return the minus of Loss\n",
    "        \"\"\"\n",
    "        return -tf.reduce_sum(tf.square(self.Y - (self.a + self.b * self.X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_fit = LinearFit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See what is inside in Variables\n",
    "\n",
    "The Variables are automatically initialized.  \n",
    "To see what values are inside this object, *.value* property can be used **after** the initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To initialize values call .initialize()\n",
    "linear_fit.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(linear_fit.a.value, linear_fit.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Manually initialize variables\n",
    "# To initialize manually, just set the desired value,\n",
    "linear_fit.a = 0.1\n",
    "linear_fit.b = 0.1\n",
    "# To reflect this operation, another `initialize` call is necessary\n",
    "linear_fit.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see the values were updated.\n",
    "print(linear_fit.a.value, linear_fit.b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find parameters $a$ and $b$ that minimizes the Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation and optimization\n",
    "\n",
    "To make an optimization, we need to *compile* the objective.\n",
    "\n",
    "In our case, the objective is linear_fit.MinusLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compilation\n",
    "linear_fit.MinusLoss().compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimization can be made after .compile() method is completed.\n",
    "linear_fit.MinusLoss().optimize(maxiter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the results\n",
    "\n",
    "The values in Variable object is updated by *optimize* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(linear_fit.a.value, linear_fit.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(X, Y, 'o', label='data')\n",
    "plt.plot(X, 0.5*X+0.4, '--k', label='true')\n",
    "plt.plot(X, linear_fit.a.value+linear_fit.b.value*X, '-r', lw=2, alpha=0.5, label='fit')\n",
    "plt.plot()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic linaer model\n",
    "\n",
    "Here, we construct a similar linear model within Bayesian framework.\n",
    "\n",
    "The likelihood is assumed as Gaussian,\n",
    "$$\n",
    "p(y_i | a, b, x_i) = \\mathcal{N}(y_i | a + b*x_i, \\sigma)\n",
    "$$\n",
    "where $\\sigma$ is the variance parameter.\n",
    "\n",
    "We assume weak prior for $a$, $b$ and $\\sigma$,\n",
    "$$\n",
    "p(a) = \\mathcal{N}(a|0,1) \\\\\n",
    "p(b) = \\mathcal{N}(b|0,1) \\\\\n",
    "p(\\sigma) = \\mathcal{N}(\\sigma|0,1) \\\\\n",
    "$$\n",
    "\n",
    "In this model, we will find $a$ and $b$ that jointly maximizes the posterior distribution,\n",
    "$$\n",
    "p(a, b, \\sigma| \\mathbf{x}, \\mathbf{y}) \n",
    "\\propto \n",
    "\\prod_{i}\\mathcal{N}(y_i | a + b*x_i, \\sigma) \n",
    "\\mathcal{N}(a|0,1) \\mathcal{N}(b|0,1)  \\mathcal{N}(\\sigma|0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct a probabilistic linear model\n",
    "class LinearModel(hb.model.Model):\n",
    "    def setUp(self):\n",
    "        # data should be stored in hb.param.Data class\n",
    "        self.X = hb.param.Data(X)\n",
    "        self.Y = hb.param.Data(Y)\n",
    "        \n",
    "        # Parameters that are defined as hb.param.Variable will be optimized by this model.\n",
    "        self.a = hb.param.Variable(shape=[1])\n",
    "        self.b = hb.param.Variable(shape=[1])\n",
    "        \n",
    "        # Addition to linear_model, we define the variance parameter.\n",
    "        # This parameter should be positive. \n",
    "        # It can be achieved by passing transform option.\n",
    "        self.sigma = hb.param.Variable(shape=[1], transform=hb.transforms.positive)\n",
    "        \n",
    "    @hb.model.AutoOptimize()\n",
    "    def logp(self):\n",
    "        \"\"\"\n",
    "        This method returns the sum of log-likelihood and log-prior.\n",
    "        \"\"\"\n",
    "        log_lik = hb.densities.gaussian(self.Y, self.a + self.b * self.X, self.sigma)\n",
    "        log_prior = hb.densities.gaussian(self.a, 0.0, 1.0)\\\n",
    "                  + hb.densities.gaussian(self.b, 0.0, 1.0)\\\n",
    "                  + hb.densities.gaussian(self.sigma, 0.0, 1.0)\n",
    "        \n",
    "        return tf.reduce_sum(log_lik) + log_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similary, we compile and optimize optimize the model.\n",
    "plinear_model = LinearModel()\n",
    "plinear_model.logp().compile()\n",
    "plinear_model.logp().optimize(maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(plinear_model.a.value, plinear_model.b.value, plinear_model.sigma.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(X, Y, 'o', label='data')\n",
    "plt.plot(X, 0.5*X+0.4, '--k', label='true')\n",
    "plt.plot(X, plinear_model.a.value+plinear_model.b.value*X, '-r', lw=2, alpha=0.5, label='fit')\n",
    "plt.plot()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is inside hb.param.Variable\n",
    "\n",
    "hb.param.Variable is an object that wraps tf.Variable.  \n",
    "In fact, `hb.param.Variable._tensor` is tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(linear_fit.a._tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable object has `.tensor()` method, that returns the transformed tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(plinear_model.sigma._tensor) # <- parameters that spans in real space\n",
    "print(plinear_model.sigma.tensor()) # <- transformed parameters that is cast to the positive space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any parameterized object such as `hb.model.Model` have `.tf_mode()`.  \n",
    "Within `tf_mode`, Variable object is seen as its .tensor() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Without tf_mode: '+str(type(plinear_model.a)))\n",
    "with plinear_model.tf_mode():\n",
    "    print('With tf_mode: ' + str(type(plinear_model.a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In decorated methods by `@hb.model.AutoOptimize()`, \n",
    "tf_mode is automatically switched on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is inside @hb.model.AutoOptimize()\n",
    "\n",
    "The methods decorated by `@hb.model.AutoOptimize()` returns   \n",
    "`hb.model.Optimizer` object, \n",
    "that contains the objective function, variables to be minimized, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(plinear_model.logp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = plinear_model.logp()\n",
    "optimizer.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ optimizer.likelihood_method is the method to be optimized.\n",
    "+ optimizer.method_op is a tf.Op that calculates the objective value.  \n",
    "  In this case, `tf.reduce_sum(log_lik) + log_prior`.\n",
    "+ optimizer.optimize_op is a tf.Op that handle the optimization.\n",
    "+ optimizer.model is a reference to the parent model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to be optimized, what optimizers to be used (such as Adam or AdaGrad) \n",
    "can be controlled by `.compile()` method.\n",
    "\n",
    "The defaults are all the variables and tf.AdamOptimizer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
